<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Ying Zhang</title>
    <description>Keep Walking, Thinking, and Learning.
</description>
    <link>http://localhost:4000/</link>
    <atom:link href="http://localhost:4000/feed.xml" rel="self" type="application/rss+xml"/>
    <pubDate>Fri, 05 Mar 2021 21:18:06 +0800</pubDate>
    <lastBuildDate>Fri, 05 Mar 2021 21:18:06 +0800</lastBuildDate>
    <generator>Jekyll v3.8.5</generator>
    
      <item>
        <title>3D人体相关研究总结 Human-3D-Overview</title>
        <description>&lt;h1 id=&quot;3d人体相关研究总结bodyposereconstructionclothanimation&quot;&gt;3D人体相关研究总结（Body、Pose、Reconstruction、Cloth、Animation）&lt;/h1&gt; &lt;h2 id=&quot;前言&quot;&gt;前言&lt;/h2&gt; &lt;p&gt;本文简要介绍与3D数字人相关的研究，包括常用3D表示、常用3D人体模型、3D人体姿态估计，带衣服3D人体重建，3D衣服建模，以及人体动作驱动等。&lt;/p&gt; &lt;hr /&gt; &lt;h2 id=&quot;常用3d表示&quot;&gt;常用3D表示&lt;/h2&gt; &lt;p&gt;目前3D 学习中，物体或场景的表示包括&lt;strong&gt;显式表示&lt;/strong&gt;与&lt;strong&gt;隐式表示&lt;/strong&gt;两种，主流的显式表示包括基于voxel、基于point cloud、和基于polygon mesh三种，隐式表示包括基于Occupancy Function[1]、和基于Signed Distance Functions[2]两种。下表简要总结了各种表示方法的原理及其相应优缺点。&lt;/p&gt; &lt;table&gt; &lt;tr&gt; &lt;th width=&quot;5%&quot;&gt;&lt;center&gt;表示方法&lt;/center&gt;&lt;/th&gt;&lt;th width=&quot;19%&quot;&gt;&lt;center&gt;Voxel&lt;/center&gt;&lt;/th&gt;&lt;th width=&quot;19%&quot;&gt;&lt;center&gt;Point Cloud&lt;/center&gt;&lt;/th&gt;&lt;th width=&quot;19%&quot;&gt;&lt;center&gt;Polygon Mesh&lt;/center&gt;&lt;/th&gt;&lt;th width=&quot;19%&quot;&gt;&lt;center&gt;Occupancy Function&lt;/center&gt;&lt;/th&gt;&lt;th width=&quot;19%&quot;&gt;&lt;center&gt;Signed Distance Function&lt;/center&gt;&lt;/th&gt;...</description>
        <pubDate>Fri, 05 Mar 2021 00:00:00 +0800</pubDate>
        <link>http://localhost:4000/posts/2021-03-05-human-3d/</link>
        <guid isPermaLink="true">http://localhost:4000/posts/2021-03-05-human-3d/</guid>
        
        <category>deep-learning</category>
        
        <category>human-3d</category>
        
        
        <category>Deep-Learning</category>
        
      </item>
    
      <item>
        <title>文本视频搜索 Text-to-Video Retrieval</title>
        <description>&lt;h1 id=&quot;文本视频搜索-text-to-video-retrieval&quot;&gt;文本视频搜索 Text-to-Video Retrieval&lt;/h1&gt; &lt;h2 id=&quot;前言&quot;&gt;前言&lt;/h2&gt; &lt;p&gt;文本视频搜索（Text-to-Video Retrieval）是指给定一句文本描述，在视频库中查找相应视频。与图像文本匹配（Image-Text Matching）相似，研究者们致力于探索如何更好地度量文本和视频之间的相似性。然而相较于文本图像搜索，一方面视频数据采集标注和存储难度大，目前人工标记的高质量数据集较少；另一方面视频内容复杂多变、时长变化大、处理难度高，研究工作的进展也相对较慢。&lt;/p&gt; &lt;p&gt;&lt;img src=&quot;/assets/textvideoretrieval/text-to-video-retrieval.png&quot; alt=&quot;text-to-video-retrieval&quot; style=&quot;zoom:45%;&quot; /&gt;&lt;/p&gt; &lt;hr /&gt; &lt;h2 id=&quot;相关工作介绍&quot;&gt;相关工作介绍&lt;/h2&gt; &lt;p&gt;基于深度学习的文本视频搜索研究主要围绕两个思路来进行，一是如何融合视频的多模态特征，如利用图像，音频，动作等信息来学习更强大的视频特征；二是如何更有效地编码视频和文本特征，如采用不同类型的特征编码网络来学习互补特征。&lt;/p&gt; &lt;hr /&gt; &lt;h4 id=&quot;1-learning-joint-embedding-with-multimodal-cues-for-cross-modal-video-text-retrieval-icmr2018-pdf-code&quot;&gt;[1] Learning Joint Embedding with Multimodal Cues for...</description>
        <pubDate>Fri, 07 Feb 2020 00:00:00 +0800</pubDate>
        <link>http://localhost:4000/posts/2020-02-07-Text-Video-Retrieval/</link>
        <guid isPermaLink="true">http://localhost:4000/posts/2020-02-07-Text-Video-Retrieval/</guid>
        
        <category>deep-learning</category>
        
        <category>text-video-retrieval</category>
        
        
        <category>Deep-Learning</category>
        
      </item>
    
      <item>
        <title> 深度度量学习 Deep Metric Learning</title>
        <description>&lt;h1 id=&quot;深度度量学习&quot;&gt;深度度量学习&lt;/h1&gt; &lt;h2 id=&quot;距离度量学习&quot;&gt;距离度量学习&lt;/h2&gt; &lt;p&gt;在搜索任务中，给定查询样本和候选集合，我们一般采用的步骤是：1）提取样本特征；2）计算查询与候选样本特征之间的距离；3）返回距离最小的候选作为搜索结果。&lt;/p&gt; &lt;p&gt;常用的度量样本之间距离的方法包括欧式距离，余弦距离，汉明距离等。然而单一的距离度量方式难以适用不同场景下的搜索任务，已有的距离方式本身也可能存在缺陷，如欧式距离假设特征所有维度的权重相同，因此如何从数据中学习出有效的距离度量成为许多研究者关注的问题。&lt;/p&gt; &lt;p&gt;&lt;strong&gt;距离度量学习（Distance Metric Learning）&lt;/strong&gt;算法一般是学习一个马氏矩阵，从而两个样本点 &lt;script type=&quot;math/tex&quot;&gt;\boldsymbol{x}_{i}&lt;/script&gt; 和 $\boldsymbol{x}_{j}$ 之间的距离定义为&lt;/p&gt; &lt;center&gt;$$D_{\boldsymbol{M}}(\boldsymbol{x}_{i}, \boldsymbol{x}_{j}) = (\boldsymbol{x}_{i}-\boldsymbol{x}_{j})^\top \boldsymbol{M} (\boldsymbol{x}_{i}-\boldsymbol{x}_{j})$$&lt;/center&gt; &lt;p&gt;距离度量学习在人脸验证和行人再识别场景中研究较多，如 &lt;a href=&quot;http://jmlr.csail.mit.edu/papers/volume10/weinberger09a/weinberger09a.pdf&quot;&gt;Margin Nearest Neighbor Learning (LMNN)&lt;/a&gt;，&lt;a href=&quot;http://www.cs.utexas.edu/users/pjain/pubs/metriclearning_icml.pdf&quot;&gt;Information Theoretic Metric...</description>
        <pubDate>Sun, 03 Nov 2019 00:00:00 +0800</pubDate>
        <link>http://localhost:4000/posts/2019-11-03-Deep-Metric-Learning/</link>
        <guid isPermaLink="true">http://localhost:4000/posts/2019-11-03-Deep-Metric-Learning/</guid>
        
        <category>deep-learning</category>
        
        <category>metric-learning</category>
        
        
        <category>Deep-Learning</category>
        
      </item>
    
  </channel>
</rss>
