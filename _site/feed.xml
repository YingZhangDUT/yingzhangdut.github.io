<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Ying Zhang</title>
    <description>Keep Walking, Thinking, and Learning.
</description>
    <link>http://localhost:4000/</link>
    <atom:link href="http://localhost:4000/feed.xml" rel="self" type="application/rss+xml"/>
    <pubDate>Sat, 08 Feb 2020 13:12:41 +0800</pubDate>
    <lastBuildDate>Sat, 08 Feb 2020 13:12:41 +0800</lastBuildDate>
    <generator>Jekyll v4.0.0</generator>
    
      <item>
        <title>文本视频搜索 Text-to-Video Retrieval</title>
        <description>&lt;h1 id=&quot;文本视频搜索-text-to-video-retrieval&quot;&gt;文本视频搜索 Text-to-Video Retrieval&lt;/h1&gt; &lt;h2 id=&quot;前言&quot;&gt;前言&lt;/h2&gt; &lt;p&gt;文本视频搜索（Text-to-Video Retrieval）是指给定一句文本描述，在视频库中查找相应视频。与图像文本匹配（Image-Text Matching）相似，研究者们致力于探索如何更好地度量文本和视频之间的相似性。然而相较于文本图像搜索，一方面视频数据采集标注和存储难度大，目前人工标记的高质量数据集较少；另一方面视频内容复杂多变、时长变化大、处理难度高，研究工作的进展也相对较慢。&lt;/p&gt; &lt;p&gt;&lt;img src=&quot;/assets/textvideoretrieval/text-to-video-retrieval.png&quot; alt=&quot;text-to-video-retrieval&quot; style=&quot;zoom:45%;&quot; /&gt;&lt;/p&gt; &lt;hr /&gt; &lt;h2 id=&quot;相关工作介绍&quot;&gt;相关工作介绍&lt;/h2&gt; &lt;p&gt;基于深度学习的文本视频搜索研究主要围绕两个思路来进行，一是如何融合视频的多模态特征，如利用图像，音频，动作等信息来学习更强大的视频特征；二是如何更有效地编码视频和文本特征，如采用不同类型的特征编码网络来学习互补特征。&lt;/p&gt; &lt;hr /&gt; &lt;h4 id=&quot;1-learning-joint-embedding-with-multimodal-cues-for-cross-modal-video-text-retrieval-icmr2018-pdf-code&quot;&gt;[1] Learning Joint Embedding with Multimodal Cues for...</description>
        <pubDate>Sat, 08 Feb 2020 00:00:00 +0800</pubDate>
        <link>http://localhost:4000/deep-learning/2020/02/08/Text-Video-Retrieval.html</link>
        <guid isPermaLink="true">http://localhost:4000/deep-learning/2020/02/08/Text-Video-Retrieval.html</guid>
        
        <category>deep-learning</category>
        
        <category>text-to-video-retrieval</category>
        
        
        <category>Deep-Learning</category>
        
      </item>
    
      <item>
        <title> 深度度量学习 Deep Metric Learning</title>
        <description>&lt;h1 id=&quot;深度度量学习&quot;&gt;深度度量学习&lt;/h1&gt; &lt;h2 id=&quot;距离度量学习&quot;&gt;距离度量学习&lt;/h2&gt; &lt;p&gt;在搜索任务中，给定查询样本和候选集合，我们一般采用的步骤是：1）提取样本特征；2）计算查询与候选样本特征之间的距离；3）返回距离最小的候选作为搜索结果。&lt;/p&gt; &lt;p&gt;常用的度量样本之间距离的方法包括欧式距离，余弦距离，汉明距离等。然而单一的距离度量方式难以适用不同场景下的搜索任务，已有的距离方式本身也可能存在缺陷，如欧式距离假设特征所有维度的权重相同，因此如何从数据中学习出有效的距离度量成为许多研究者关注的问题。&lt;/p&gt; &lt;p&gt;&lt;strong&gt;距离度量学习（Distance Metric Learning）&lt;/strong&gt;算法一般是学习一个马氏矩阵，从而两个样本点 &lt;script type=&quot;math/tex&quot;&gt;\boldsymbol{x}_{i}&lt;/script&gt; 和 $\boldsymbol{x}_{j}$ 之间的距离定义为&lt;/p&gt; &lt;center&gt;$$D_{\boldsymbol{M}}(\boldsymbol{x}_{i}, \boldsymbol{x}_{j}) = (\boldsymbol{x}_{i}-\boldsymbol{x}_{j})^\top \boldsymbol{M} (\boldsymbol{x}_{i}-\boldsymbol{x}_{j})$$&lt;/center&gt; &lt;p&gt;距离度量学习在人脸验证和行人再识别场景中研究较多，如 &lt;a href=&quot;http://jmlr.csail.mit.edu/papers/volume10/weinberger09a/weinberger09a.pdf&quot;&gt;Margin Nearest Neighbor Learning (LMNN)&lt;/a&gt;，&lt;a href=&quot;http://www.cs.utexas.edu/users/pjain/pubs/metriclearning_icml.pdf&quot;&gt;Information Theoretic Metric...</description>
        <pubDate>Sun, 03 Nov 2019 00:00:00 +0800</pubDate>
        <link>http://localhost:4000/deep-learning/2019/11/03/Deep-Metric-Learning.html</link>
        <guid isPermaLink="true">http://localhost:4000/deep-learning/2019/11/03/Deep-Metric-Learning.html</guid>
        
        <category>deep-learning</category>
        
        <category>metric-learning</category>
        
        
        <category>Deep-Learning</category>
        
      </item>
    
  </channel>
</rss>
